{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1146cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from rapidfuzz import process, fuzz\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b6709",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_speakers(transcript, speaker_changes):\n",
    "    \"\"\"\n",
    "    Map Whisper-style transcript speaker labels (e.g., \"SPEAKER_00\", \"SPEAKER_01\") \n",
    "    to real speaker names (from diarization output) based on maximum temporal overlap.\n",
    "\n",
    "    The function compares transcript segments to diarization intervals and \n",
    "    determines which real speaker each Whisper speaker corresponds to most often.\n",
    "\n",
    "    Args:\n",
    "        transcript (list[dict]): \n",
    "            List of transcript segments, each containing:\n",
    "            - 'start' (float): Start time in seconds.\n",
    "            - 'end' (float): End time in seconds.\n",
    "            - 'speaker' (str): Whisper-assigned speaker label (e.g., \"SPEAKER_00\").\n",
    "\n",
    "        speaker_changes (list[list]): \n",
    "            List of diarization speaker changes as `[timestamp, speaker_name]`,\n",
    "            sorted by timestamp.\n",
    "\n",
    "    Returns:\n",
    "        dict:\n",
    "            Mapping of Whisper speaker labels to real speaker names, e.g.:\n",
    "            {\n",
    "                \"SPEAKER_00\": \"john\",\n",
    "                \"SPEAKER_01\": \"mary\"\n",
    "            }\n",
    "\n",
    "    Example:\n",
    "        >>> transcript = [{\"start\": 0.0, \"end\": 5.0, \"speaker\": \"SPEAKER_00\"}]\n",
    "        >>> speaker_changes = [[0.0, \"John\"], [10.0, \"Mary\"]]\n",
    "        >>> map_speakers(transcript, speaker_changes)\n",
    "        {'SPEAKER_00': 'John'}\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Convert speaker_changes into intervals [(start, end, speaker_name)]\n",
    "    intervals = []\n",
    "    for i, (time_str, speaker_name) in enumerate(speaker_changes):\n",
    "        start = float(time_str)\n",
    "        end = float(speaker_changes[i+1][0]) if i+1 < len(speaker_changes) else float('inf')\n",
    "        intervals.append((start, end, speaker_name))\n",
    "    \n",
    "    # Track overlaps: { transcript_speaker -> { real_speaker -> total_overlap } }\n",
    "    overlaps = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    for seg in transcript:\n",
    "        t_start, t_end, t_speaker = seg[\"start\"], seg[\"end\"], seg[\"speaker\"]\n",
    "        \n",
    "        for i_start, i_end, i_speaker in intervals:\n",
    "            # Find overlap between transcript segment and real speaker interval\n",
    "            overlap = max(0, min(t_end, i_end) - max(t_start, i_start))\n",
    "            if overlap > 0:\n",
    "                overlaps[t_speaker][i_speaker] += overlap\n",
    "    \n",
    "    # Pick the best matching real speaker for each transcript speaker\n",
    "    mapping = {}\n",
    "    for t_speaker, speaker_dict in overlaps.items():\n",
    "        best_match = max(speaker_dict.items(), key=lambda x: x[1])[0]\n",
    "        mapping[t_speaker] = best_match\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "\n",
    "def merge_consecutive_whisper(data):\n",
    "    \"\"\"\n",
    "    Merge consecutive Whisper transcript segments from the same speaker.\n",
    "\n",
    "    If adjacent segments share the same 'speaker', they are combined into \n",
    "    a single segment with extended 'end' time and concatenated text.\n",
    "\n",
    "    Args:\n",
    "        data (list[dict]):\n",
    "            List of transcript segments, each containing:\n",
    "            - 'start' (float): Segment start time.\n",
    "            - 'end' (float): Segment end time.\n",
    "            - 'speaker' (str): Speaker label.\n",
    "            - 'text' (str): Segment text.\n",
    "            Optionally may include 'words' (list), which are dropped when merging.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]:\n",
    "            A list of merged segments, with consecutive same-speaker segments combined.\n",
    "\n",
    "    Example:\n",
    "        >>> data = [\n",
    "        ...     {\"start\": 0, \"end\": 2, \"speaker\": \"SPEAKER_00\", \"text\": \"Hello\"},\n",
    "        ...     {\"start\": 2, \"end\": 4, \"speaker\": \"SPEAKER_00\", \"text\": \"world\"},\n",
    "        ...     {\"start\": 4, \"end\": 6, \"speaker\": \"SPEAKER_01\", \"text\": \"Hi\"}\n",
    "        ... ]\n",
    "        >>> merge_consecutive_whisper(data)\n",
    "        [{'start': 0, 'end': 4, 'speaker': 'SPEAKER_00', 'text': 'Hello world'},\n",
    "         {'start': 4, 'end': 6, 'speaker': 'SPEAKER_01', 'text': 'Hi'}]\n",
    "    \"\"\"\n",
    "\n",
    "    if not data:\n",
    "        return []\n",
    "\n",
    "    merged = [data[0]]\n",
    "\n",
    "    for segment in data[1:]:\n",
    "        last = merged[-1]\n",
    "        if segment[\"speaker\"] == last[\"speaker\"]:\n",
    "            # Extend the last segment\n",
    "            last[\"end\"] = segment[\"end\"]\n",
    "            last[\"text\"] += \" \" + segment[\"text\"]\n",
    "            \n",
    "            \n",
    "            #last[\"words\"].extend(segment[\"words\"])\n",
    "        else:\n",
    "            # New speaker → start new segment\n",
    "            del segment['words']\n",
    "            merged.append(segment)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def standardize_speaker_changes(speaker_changes):\n",
    "    \"\"\"\n",
    "    Clean and standardize a list of speaker change events using fuzzy name matching.\n",
    "\n",
    "    The function:\n",
    "      1. Converts timestamps to floats and normalizes speaker names (lowercase, no spaces).\n",
    "      2. Uses fuzzy matching to merge similar speaker names (e.g., \"John\" ≈ \"Jon\").\n",
    "      3. Merges consecutive entries belonging to the same standardized speaker.\n",
    "\n",
    "    Args:\n",
    "        speaker_changes (list[list]):\n",
    "            List of `[timestamp, speaker_name]` pairs.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple]:\n",
    "            A list of standardized speaker change tuples `(start_time, standardized_name)`.\n",
    "\n",
    "    Example:\n",
    "        >>> speaker_changes = [\n",
    "        ...     [\"0.0\", \"John Doe\"],\n",
    "        ...     [\"5.0\", \"john\"],\n",
    "        ...     [\"10.0\", \"Mary\"]\n",
    "        ... ]\n",
    "        >>> standardize_speaker_changes(speaker_changes)\n",
    "        [(0.0, 'johndoe'), (10.0, 'mary')]\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(speaker_changes, columns=['timestamp', 'speaker'])\n",
    "    df['speaker'] = df['speaker'].apply(lambda x: x.lower().replace(' ', ''))\n",
    "    df['timestamp'] = df['timestamp'].astype(float)\n",
    "\n",
    "    # 1️⃣ Standardize speaker names using fuzzy matching\n",
    "    unique_speakers = df['speaker'].unique()\n",
    "    standard_names = {}\n",
    "\n",
    "    for s in unique_speakers:\n",
    "        # Compare against already mapped speakers\n",
    "        if standard_names:\n",
    "            match, score, _ = process.extractOne(s, standard_names.keys(), scorer=fuzz.ratio)\n",
    "            if score >= 80:  # similarity threshold\n",
    "                standard_names[s] = standard_names[match]\n",
    "            else:\n",
    "                standard_names[s] = s\n",
    "        else:\n",
    "            standard_names[s] = s\n",
    "    df['speaker_std'] = df['speaker'].map(standard_names)\n",
    "\n",
    "    # 2️⃣ Merge consecutive identical speakers\n",
    "    merged = []\n",
    "    prev_speaker = None\n",
    "    for _, row in df.iterrows():\n",
    "        if prev_speaker is None or row['speaker_std'] != prev_speaker['speaker_std']:\n",
    "            # start a new block\n",
    "            prev_speaker = {\n",
    "                'start': row['timestamp'],\n",
    "                'speaker_std': row['speaker_std']\n",
    "            }\n",
    "            merged.append(prev_speaker)\n",
    "        else:\n",
    "            # same speaker, skip timestamp (keep start)\n",
    "            continue\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    merged_df = pd.DataFrame(merged)\n",
    "    merged_df['speaker_std'] = merged_df['speaker_std'].fillna('Other')\n",
    "    speaker_changes = [(x['start'], x['speaker_std']) for (idx, x) in merged_df.iterrows()]\n",
    "    return speaker_changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622be0eb",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_path = 'path_to_whisper_transcriptions'\n",
    "speaker_changes_path = 'path_to_zoom_diarization'\n",
    "save_loc = 'save_loc_path'\n",
    "os.makedirs(save_loc, exist_ok=True)\n",
    "\n",
    "whisper_files = os.listdir(whisper_path)\n",
    "speaker_changes_files = os.listdir(speaker_changes_path)\n",
    "common = list(set(whisper_files) & set(speaker_changes_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74806e9b",
   "metadata": {},
   "source": [
    "#### 1. Map Speaker namees accross videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8848f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speaker = []\n",
    "for file in common:\n",
    "    speaker_changes = np.load(os.path.join(speaker_changes_path, file), allow_pickle=True)\n",
    "    whisper = np.load(os.path.join(whisper_path, file), allow_pickle=True)\n",
    "    all_speaker = all_speaker + list(speaker_changes)\n",
    "all_speaker = [str(x[1]) for x in all_speaker]\n",
    "all_speaker = [x.split('-')[0].split('|')[0].split(',')[0].strip() for x in all_speaker]\n",
    "\n",
    "unique_names = []\n",
    "mapping = {}  # original -> canonical\n",
    "\n",
    "for name in np.unique(all_speaker):\n",
    "    if not unique_names:\n",
    "        unique_names.append(name)\n",
    "        mapping[str(name)] = str(name)\n",
    "        continue\n",
    "    \n",
    "    # find best match among canonical names\n",
    "    match, score, _ = process.extractOne(name, unique_names, scorer=fuzz.token_sort_ratio)\n",
    "    if score >= 80:\n",
    "        canonical = match\n",
    "    else:\n",
    "        canonical = str(name)\n",
    "        unique_names.append(name)\n",
    "    mapping[str(name)] = str(canonical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d4a7c",
   "metadata": {},
   "source": [
    "### 2. Map speakers and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2ba89",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'02:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m transcript_map = map_speakers(whisper_transcript, speaker_changes)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m whisper_transcript:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     x[\u001b[33m'\u001b[39m\u001b[33mspeaker\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtranscript_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspeaker\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m#np.save(os.path.join(save_loc, file), whisper_transcript)\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: '02:00'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in common:\n",
    "\n",
    "    speaker_changes = np.load(os.path.join(speaker_changes_path, file), allow_pickle=True)\n",
    "    whisper = np.load(os.path.join(whisper_path, file), allow_pickle=True)\n",
    "    speaker_changes = standardize_speaker_changes(speaker_changes)\n",
    "\n",
    "    tmp = pd.DataFrame(list(np.unique([x[1] for x in speaker_changes])))\n",
    "    if len(tmp) > 100:\n",
    "        print(\"Skipping: \", file)\n",
    "        continue\n",
    "    whisper_transcript = merge_consecutive_whisper(list(whisper))\n",
    "    transcript_map = map_speakers(whisper_transcript, speaker_changes)\n",
    "\n",
    "    for x in whisper_transcript:\n",
    "        x['speaker'] = mapping[transcript_map[x['speaker']]]\n",
    "\n",
    "    np.save(os.path.join(save_loc, file), whisper_transcript)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
